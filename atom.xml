<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Green Sky]]></title>
  <subtitle><![CDATA[Welcome to Changyue Song's Homepage]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://songcy.net/"/>
  <updated>2015-03-31T15:15:29.884Z</updated>
  <id>http://songcy.net/</id>
  
  <author>
    <name><![CDATA[Song, Changyue]]></name>
    <email><![CDATA[songcy08@qq.com]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Elements of Frequency-domain Analysis]]></title>
    <link href="http://songcy.net/posts/elements-frequency-domain-analysis/"/>
    <id>http://songcy.net/posts/elements-frequency-domain-analysis/</id>
    <published>2015-01-16T16:00:00.000Z</published>
    <updated>2015-01-16T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<h2 id="introduction">1. Introduction</h2>
<p>Frequency-domain analysis is a commonly used technique in signal processing. For example, in heart rate variation (HRV) analysis, high frequency (HF) and low frequency (LF) components are usually extracted from RR intervals based on power spectral analysis. As an industrial engineering, I am not familiar with this area, but I need this tool in my research. Although a lot of open-source software/libraries are available, I think it still necessary to understand what is going on. Therefore, I spent some time in frequency-domain analysis and make a little summary here.</p>
<h2 id="fourier-transform">2. Fourier Transform</h2>
<p>Fourier transform is the basis of frequency-domain analysis. Fourier transform maps a signal from time domain to frequency domain. There are four kinds of Fourier transforms:</p>
<ul>
<li>Fourier series: <span class="math">\[ X(k)=\frac{1}{T} \int_0^T x(t) e^{-j2\pi k t/T} dt \]</span></li>
<li>Discrete-time Fourier transform: <span class="math">\[ X(f)=\sum_{n=-\infty}^{\infty} x(n) e^{-j2\pi fn} \]</span></li>
<li>Continuous-time Fourier transform: <span class="math">\[ X(f)=\int_{-\infty}^{\infty} x(t) e^{-j2\pi ft}dt \]</span></li>
<li>Discrete Fourier transform: <span class="math">\[ X(k)=\sum_{n=0}^{N-1} x(n) e^{-j2\pi kn/N} \]</span></li>
</ul>
<p>Each kind of Fourier transform has its inverse Fourier transform, which reconstruct the original signal based on the frequency components.</p>
<p>Take Fourier series as an example. It can be shown that any periodic function <span class="math">\(x(t)\)</span> can be represented as linear combination of <span class="math">\(\cos(2\pi m t/T)\)</span> and <span class="math">\(\sin(2\pi n t/T)\)</span>, where <span class="math">\(T\)</span> is the period of <span class="math">\(x(t)\)</span>, i.e. $ x(t+T)=x(t) $ for any <span class="math">\(t\)</span>, and <span class="math">\(m,n\)</span> are integers, <span class="math">\[
    x(t)=\sum_{m=0}^{\infty} a_m \cos(2\pi mt/T) + \sum_{n=1}^{\infty} b_n \sin(2\pi nt/T)
\]</span> Here <span class="math">\(a_m\)</span> and <span class="math">\(b_n\)</span> are real numbers. According to Euler’s formula <span class="math">\[
    e^{jx}=\cos x + j \sin x
\]</span> where <span class="math">\(j=\sqrt{-1}\)</span>, then we get <span class="math">\[
    x(t)=\sum_{k=-\infty}^{\infty} X(k) e^{j2\pi k t/T}
\]</span> Now <span class="math">\(x(t)\)</span> is represented by a linear combination of <span class="math">\(e^{j2\pi k t/T}\)</span>, and <span class="math">\(X(k)\)</span> are the coefficients (complex numbers), <span class="math">\(k\)</span> is integer. Recall the Euler’s formula, <span class="math">\(e^{j2\pi k t/T}\)</span> has period <span class="math">\(T/k\)</span> or frequency <span class="math">\(k/T\)</span>. Thus <span class="math">\(x(t)\)</span> has been discomposited into combination of components in different frequency! It can be shown that the coefficient <span class="math">\(X(k)\)</span> can be calculated as <span class="math">\[
    X(k)=\frac{1}{T} \int_0^T x(t) e^{-j2\pi k t/T} dt
\]</span> This equation is Fourier series. Therefore, Fourier series calculates the coefficients for each frequency component. And the previous equation is inverse Fourier series, which reconstruct the original time-domain signal based on the coefficients of frequency components.</p>
<p>Other kinds of Fourier transforms are similar. And the characteristics of each Fourier transform are listed in the following table.</p>
<table>
<tr>
<th style="text-align:center;border:1px solid">
 
</th>
<th colspan="2" style="text-align:center;border:1px solid">
Time domain
</th>
<th colspan="2" style="text-align:center;border:1px solid">
Frequency domain
</th>
</tr>
<tr>
<td style="text-align:center;border:1px solid">
Fourier series
</td>
<td style="text-align:center;border:1px solid">
continuous
</td>
<td style="text-align:center;border:1px solid">
periodic
</td>
<td style="text-align:center;border:1px solid">
discrete
</td>
<td style="text-align:center;border:1px solid">
nonperiodic
</td>
</tr>
<tr>
<td style="text-align:center;border:1px solid">
Discrete-time Fourier transform
</td>
<td style="text-align:center;border:1px solid">
discrete
</td>
<td style="text-align:center;border:1px solid">
nonperiodic
</td>
<td style="text-align:center;border:1px solid">
continuous
</td>
<td style="text-align:center;border:1px solid">
periodic
</td>
</tr>
<tr>
<td style="text-align:center;border:1px solid">
Continuous-time Fourier transform
</td>
<td style="text-align:center;border:1px solid">
continuous
</td>
<td style="text-align:center;border:1px solid">
nonperiodic
</td>
<td style="text-align:center;border:1px solid">
continuous
</td>
<td style="text-align:center;border:1px solid">
nonperiodic
</td>
</tr>
<tr>
<td style="text-align:center;border:1px solid">
Discrete Fourier transform
</td>
<td style="text-align:center;border:1px solid">
discrete
</td>
<td style="text-align:center;border:1px solid">
periodic
</td>
<td style="text-align:center;border:1px solid">
discrete
</td>
<td style="text-align:center;border:1px solid">
periodic
</td>
</tr>
</table>
<p>For example, Fourier series takes a continuous periodic function <span class="math">\(x(t)\)</span> as input, and produces discrete non-periodic coefficients <span class="math">\(X(k)\)</span> as output. The table shows something interesting. Discrete in one domain always related to periodic in the other domain, while continuous in one domain always related to nonperiodic in the other domain.</p>
<p>Since digital signals are stored in discrete values in computer, discrete-time Fourier transform (DTFT) and discrete Fourier transform (DFT) are more commonly used. DTFT takes discrete nonperiodic signal as input, and produces its frequency components as continuous periodic series. DFT takes discrete periodic signal as input, and produces its frequency components as a discrete periodic signal. If some conditions are satisfied, e.g. <span class="math">\(N=2^n\)</span>, fast Fourier transform (FFT) algorithms can be employed to calculate DFT efficiently.</p>
<p>Fourier transform can be considered from the point of view <a href="http://songcy.net/posts/vector-to-function-basis-kernel/" title="function basis and kernel method" target="_blank" rel="external">function basis and kernel method</a>, which is the concern of my another article.</p>
<p>There are other transforms such as z-transform and Laplace transform. They have very similar form with Fourier transform. For example, in z-transform <span class="math">\[
    X(z)=\sum_{n=-\infty}^{\infty} x(n) z^{-n}
\]</span> Here <span class="math">\(z\)</span> is a complex number. Let <span class="math">\[
    z=e^{jw}
\]</span> we get DTFT.</p>
<h2 id="energy-spectrum-and-power-spectrum">3. Energy Spectrum and Power Spectrum</h2>
<p>Energy spectrum is defined as the energy on a specific frequency <span class="math">\[
    S_x (f) = |X(f)|^2
\]</span> If we sum up or integrate the energy spectrum over <span class="math">\((-\infty, \infty)\)</span> for Fourier series and continuous Fourier series, and over <span class="math">\([-1, 1]\)</span> for DFT and DTFT, we can get the total energy.</p>
<p>However, sometimes a signal does not have Fourier transform (continuous Fourier transform or DTFT), i.e. <span class="math">\(|X(f)|\)</span> go to infinity, we define power spectrum as the $ S_x (f)$ divided by the integral interval of Fourier transform. <span class="math">\[
    R_x (f)=\lim_{T \rightarrow \infty} \frac{1}{2T} |\mathcal{F} (x)|^2
\]</span> Here <span class="math">\(\mathcal{F} (x)\)</span> applies Fourier transform to <span class="math">\(x(t)\)</span> over <span class="math">\([-T, T]\)</span> at frequency <span class="math">\(f\)</span>. It can be shown that <span class="math">\(R_x (f)\)</span> can be calculated as the Fourier transform of <span class="math">\(r_x(\tau)\)</span> <span class="math">\[
    R_x (f)=\mathcal{F} (r_x(\tau))
\]</span> where <span class="math">\[
    r_x(\tau)=\lim_{T \rightarrow \infty} \frac{1}{2T} \int_{-T}^T x(t+\tau) x(t) dt
\]</span></p>
<h2 id="stationary-stochastic-process">4. Stationary Stochastic Process</h2>
<p>Until now we are talking about deterministic signals, i.e. <span class="math">\(x(t)\)</span> is a specific function of <span class="math">\(t\)</span>. Sometimes it is necessary to consider stochastic process, i.e. <span class="math">\(x_t\)</span> is a random variable. Here I use subscript to distinguish stochastic process from deterministic signal.</p>
<p>For a stochastic process <span class="math">\(x_1, x_2, \cdots, x_N\)</span>, if the correlation between any two variables depends only on the difference in time <span class="math">\[
    Cor(x_{n+k}, x_n)=Cor(x_{1+k},x_1)=r(k)
\]</span> for any <span class="math">\(n\)</span>, and the expected value is certain <span class="math">\[
    E(x_n)=\mu
\]</span> The stochastic process is weakly stationary or wide-sense stationary (WSS).</p>
<p>For WSS process, we cannot apply Fourier transform to the original series directly since they are random numbers. But we can apply Fourier transform to its autocorrelation function <span class="math">\(r(k)\)</span>. Recall Section 3, <span class="math">\[
    r_x(k)=\lim_{T \rightarrow \infty} \frac{1}{N} \sum_{0}^{N-1} x(t+k) x(t) dt
\]</span> is the autocorrelation for WSS process with zero mean and variance 1 (for other WSS process, it will be proportional). The resulting value <span class="math">\[
    R_x (f)=\mathcal{F} (r_k)
\]</span> is the power spectrum.</p>
<h2 id="power-spectrum-estimation">5. Power Spectrum Estimation</h2>
<p>Power spectrum is calculated as the Fourier transform of the autocorrelation function (ACF). However, in practice, the series is usually not infinite, and we rarely know the true ACF. Thus we need to estimate power spectrum. There are two categories of methods for power spectrum estimation: non-parametric method and parametric method.</p>
<p>In non-parametric method, ACF is estimated directly by data. Periodogram is a non-parametric estimation, where <span class="math">\[
    \hat{r}(k)=\frac{1}{N} \sum_{n=0}^{N-1-k} x(n)x(n+k)
\]</span> here <span class="math">\(N\)</span> is the length of the signal. It is equivalent to the ACF of an infinite series <span class="math">\(y(n)\)</span> where <span class="math">\(y(n)=x(n)\)</span> when <span class="math">\(n=0,1,\cdots,N-1\)</span> and <span class="math">\(y(n)=0\)</span> for other <span class="math">\(n\)</span>.</p>
<p>In parametric method, a model, e.g. autoregressive moving average (ARMA) model, is fitted at first. Then the ACF can be calculated.</p>
<h2 id="some-comments">6. Some Comments</h2>
<p>The constraint in power spectrum analysis is that the process should be stationary. However, in a lot of situations, this assumption is not satisfied. Furthermore, power spectrum analysis need a long series of data to obtain good estimation. Therefore, maybe state-space model is a better choice in a number of situations.</p>
<h2 id="for-more-information">For more information</h2>
<p>About ARMA model:</p>
<ul>
<li>Cryer, J. D., &amp; Chan, K. S. (2008). <em>Time series analysis: with applications in R</em>. Springer.</li>
</ul>
<p>About Fourier transform:</p>
<ul>
<li><a href="http://www.thefouriertransform.com/" class="uri" target="_blank" rel="external">http://www.thefouriertransform.com/</a></li>
</ul>
<p>About power spectrum:</p>
<ul>
<li>Hayes, M. H. (2009). <em>Statistical digital signal processing and modeling</em>. John Wiley &amp; Sons.</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="introduction">1. Introduction</h2>
<p>Frequency-domain analysis is a commonly used technique in signal processing. For example, in ]]>
    </summary>
    
      <category term="Fourier transform" scheme="http://songcy.net/tags/Fourier-transform/"/>
    
      <category term="power spectral" scheme="http://songcy.net/tags/power-spectral/"/>
    
      <category term="periodogram" scheme="http://songcy.net/tags/periodogram/"/>
    
      <category term="ARMA" scheme="http://songcy.net/tags/ARMA/"/>
    
      <category term="academic theory" scheme="http://songcy.net/categories/academic-theory/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Visual Tracking of Tanks in Battle City Using Particles Filters]]></title>
    <link href="http://songcy.net/posts/visual-tracking-tanks-in-battle-city/"/>
    <id>http://songcy.net/posts/visual-tracking-tanks-in-battle-city/</id>
    <published>2015-01-11T16:00:00.000Z</published>
    <updated>2015-01-11T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<h2 id="introduction">1. Introduction</h2>
<h3 id="review-of-visual-object-tracking">1.1 Review of Visual Object Tracking</h3>
<p>Visual object tracking is a rapidly developing area in computer vision community. The purpose of visual object tracking is to track objects of interests in video or consecutive images. It has various applications such as car surveillance [1], smart room [2], augmented reality [3], etc. The tracking of real-world objects is challenging as a result of environment noise, occlusion, objects interaction, object deformation, change of light, etc. Recently, Kevin Cannons made a comprehensive review of the models and techniques widely used in 2D visual tracking [4]. Other reviews in this field include [5], [6], and [7]. According to [4], common tools of visual object tracking include foreground detection, feature extraction, tracking models, and data association.</p>
<p>Foreground detection aims to detection the objects of interests, which is in contrast to background. Methods for foreground detection fall into three categories. The first category is background subtraction, which assumes a template of background without objects in it [8]. Then the targets are obtained by subtracting the background from the image. The second category is based on image difference. These methods assume moving objects in consecutive frames, which causes the difference in the active areas between temporal adjacent frames. Typical methods include two-frame difference [9], three-frame difference [10], and motion coherence energy [11]. The first two categories assume static camera with static background. To handle non-static cases, additional efforts are necessary to calibrate the background. The third category includes target spotting approaches, which assumes reliable templates for targets [12]. Detectors are trained to compare features from the suspicious region and the template to determine the presence of objects.</p>
<p>Feature extraction methods play an important role in visual object tracking. The aim of feature extraction is to characterize an object as well as to distinguish it from the background and other objects. Good features are able to uniquely identify a certain object from the environment and are insensitive to the deformation or occlusion of the target. Popular features include discrete features, interest points, and regional features. Discrete features include edges and lines of the object which can be detected by edge detectors. Canny’s edge detector is one of the most widely used edge detectors currently [13]. Interest points is another class of image features such as the center of a corner. Regional features describe the characteristic of a region in an image. Color histogram is a typical regional feature, which characterize a region by its histogram of RGB (red, green, blue) values or HSV (hue, saturation, brightness) values [14]. Color histogram gains its popularity since its simplicity, light computation, and insensitivity to occlusions or scales.</p>
<p>According to whether a method makes predictions, a tracking model can be classified into deterministic method or stochastic method [15]. Deterministic methods typically track by iteratively seeking a region in an image which has maximum similarity with a given template. Mean-shift algorithm is a typical deterministic method [14]. In contrast, stochastic methods employ statistical models such as Kalman filters and particle filters for object tracking [16]. These models execute prediction and updating repetitively. Kalman filters are based on the Gaussian assumption which particle filters use Monte Carlo representation to relieve this constraint.</p>
<p>When multiple objects are detected, data association techniques help to recognize the same object in different frames, in order to reveal the temporal motion for each object. The simplest data association method is nearest neighbor algorithm [17] which associate two objects by minimum spatial distance.</p>
<h3 id="description-of-the-project">1.2 Description of the Project</h3>
<p>“Battle City” is a famous electronic game where one or two players each controls a tank and fires on enemies in a predefined map. A scene of the game is displayed in Figure 1.</p>
<center>
<a href="../../post-attachments/4/battle-city.jpg"><img src="../../post-attachments/4/battle-city.jpg" alt="Figure 1: A scene of Battle City" width="625"></a>
</center>
<p>The yellow and the green rectangles at the bottom of the image are tanks controlled by the players. The red and white bricks denote walls, and the white tanks are enemies. In this paper, we apply visual object tracking methods to the game “Battle City” with the following considerations:</p>
<ul>
<li>The background is static and simple.</li>
<li>The objects are very different in color with the environment.</li>
<li>The popularity of this game will make this application interesting.</li>
</ul>
<p>Our aim is to track the one or two tanks controlled by the players. Since Kalman filters make the assumption of Gaussian distribution, initialization becomes critical. As a result, Kalman filters need foreground detection methods or manual annotation for the initial position of tanks. They also need foreground detection and data association methods to obtain measurements and update states. On the other side, particle filters are able to handle unknown initial position and nonlinear measurement models, which will relieve us from image processing works. Therefore, we select particles filters which will be described in detail in Section 2. In our method, it is not necessary to adopt any foreground detection or data association techniques.</p>
<p>Similar to target spotting in foreground detection, we use templates for each objects and compare them with suspicious regions. More specifically, we compare the features extracted from templates and suspicious regions. As mentioned before, the tanks have distinguishable colors, and color-based features usually require less computation, which makes regional color-based features favorable in our case. In this work, we adopt the features raised in [18] since its simplicity and rapid calculation. It also retains spatial information compared to traditional color histograms.</p>
<p>I use multiple templates for each targets. An object may have different appearance and features in different environments, orientations, status, etc. In our case, the appearance of a tank depends on its orientation. As shown in Figure 2, four templates are adopted for a single object which depict the appearance of the object when its orientation is upward, downward, rightward, and leftward respectively.</p>
<center>
<a href="../../post-attachments/4/multiple-templates.png"><img src="../../post-attachments/4/multiple-templates.png" alt="Figure 2: Four templates for one tank" width="625"></a>
</center>
<p>This study is mainly based on [15]. In [15], the authors combine contour features and color features in the measurement model of the particle filter. While in this study, only color features are incorporated. Furthermore, we adopt a similar structure that each object is associated with an independent particle filter. This is based on the contrasting color between objects. According to [19], the interaction between similar objects easily cause “hijacks” when lots of particles for one object converge to another. In our case, considering the significant difference between objects, “hijacks” are unlikely to happen and we avoid high-dimensional state space and complex models (e.g. Markov random field) by this structure.</p>
<h2 id="method">2. Method</h2>
<h3 id="particle-filters">2.1 Particle Filters</h3>
<p>Particle filter is a combination of Monte Carlo approach and Bayesian filter. A Bayesian filter considers two stochastic processes, the states <span class="math">\(X_t\)</span> and the measurements <span class="math">\(Y_t\)</span>, where $t=1,2,$ denotes time. The temporal relationship between adjacent states is depicted by prediction probability <span class="math">\(P(X_t|X_{t-1})\)</span>. The relationship between state and measurement is depicted by emission probability <span class="math">\(P(Y_t|X_t)\)</span>. Prediction and updating are iteratively executed. In prediction, the next state at time <span class="math">\(t\)</span>, <span class="math">\(X_t\)</span>, is predicted based on the previous <span class="math">\(t-1\)</span> measurements. <span class="math">\[
    P(X_t|Y_1, \cdots, Y_{t-1})=\int P(X_t |X_{t-1}) P(X_{t-1}|Y_1, \cdots, Y_{t-1}) dX_{t-1}
\]</span> When the measurement at time <span class="math">\(t\)</span> arrives, the posterior probability of <span class="math">\(X_t\)</span> is updated as <span class="math">\[
    P(X_t|Y_1,\cdots,Y_{t-1},Y_t) \propto P(X_t|Y_1, \cdots, Y_{t-1}) P(Y_t |X_t)
\]</span></p>
<p>In particle filter, a number of samples <span class="math">\(x_{t,1}, x_{t,2}, \cdots, x_{t,n}\)</span> are used to represent the random variable <span class="math">\(X_t\)</span>. The prediction step changes to <span class="math">\[
    \mbox{sample } \bar{x}_{t,i} \sim P(X_t | x_{t-1,i}), \quad i=1,2,\cdots, n
\]</span> And the updating step changes to <span class="math">\[
    \mbox{sample } \{x_{t,i}\}_{i=1}^n \mbox{ from } \{\bar{x}_{t,i}\}_{i=1}^n \mbox{ according to weight } w_{t,i}=P(Y_t | \bar{x}_{t,i})
\]</span></p>
<p>Practically, the prediction probability <span class="math">\(P(X_t|X_{t-1})\)</span> and emission probability <span class="math">\(P(Y_t|X_t)\)</span> are unknown, and need to be inferred from prediction model and measurement model. The next subsection will elaborate the prediction and measurement model employed in this study.</p>
<h3 id="prediction-model">2.2 Prediction Model</h3>
<p>In this study, we concern the position of tanks. An object is defined as a rectangular area which surrounds the tank. The state is defined as <span class="math">\[
    X_t = \begin{pmatrix}
    a_t \\
    b_t
    \end{pmatrix}
\]</span> where <span class="math">\(a_t\)</span> and <span class="math">\(b_t\)</span> are horizontal and vertical coordinate of the object, as shown in Figure 3.</p>
<center>
<a href="../../post-attachments/4/coordinator.png"><img src="../../post-attachments/4/coordinator.png" alt="Figure 3: The coordinate system adopted in this study" width="300"></a>
</center>
<p>The prediction model is <span class="math">\[
    X_{t}=X_{t-1}+\epsilon_{t-1}
\]</span> where <span class="math">\(\epsilon_{t-1}\)</span> is a random Gaussian noise with zero mean and covariance <span class="math">\(\Sigma_{\epsilon}\)</span>. Therefore, the prediction is <span class="math">\[
    \bar{x}_{t,i}=x_{t-1,i}+\epsilon_{t-1,i}
\]</span> for each particle, where <span class="math">\(\epsilon_{t-1,i}\)</span> is a random sample of <span class="math">\(\epsilon_{t-1}\)</span>.</p>
<h3 id="measurement-model">2.3 Measurement Model</h3>
<p>Given a template of the object, the measurement model is defined as <span class="math">\[
    Y_t=Y^*+\delta_{t-1}
\]</span> where <span class="math">\(Y^*\)</span> is the feature extracted from the template, <span class="math">\(\delta_{t-1}\)</span> is a zero-mean Gaussian noise with covariance <span class="math">\(\Sigma_{\delta}\)</span>. And <span class="math">\[
    Y_t=h(X_t)
\]</span> where <span class="math">\(h(X_t)\)</span> means the extraction of features from a rectangle area, the center of which is defined by <span class="math">\(X_t\)</span> and its size is equal to the size of the template.</p>
<p>Therefore, the weight of each predicted particle can be calculated as <span class="math">\[
    w_{t,i}=\Phi(h(\bar{x}_{t,i})-Y^*,0,\Sigma_{\delta}) \propto \exp[(h(\bar{x}_{t,i})-Y^*)^T Q^{-1} (h(\bar{x}_{t,i})-Y^*)]
\]</span> where <span class="math">\(\Phi(z,\mu,\Sigma)\)</span> is the likelihood at <span class="math">\(z\)</span> for Gaussian distribution with mean <span class="math">\(\mu\)</span> and covariance <span class="math">\(\Sigma\)</span>. In our study, we set the covariance matrix <span class="math">\(\Sigma_{\delta}=\sigma^2 I\)</span> where <span class="math">\(I\)</span> is the identity matrix and <span class="math">\(\sigma\)</span> is a scalar. Then the equation above simplifies to <span class="math">\[
    w_{t,i} \propto \exp \left[ \frac{1}{\sigma^2}\sum_{j=1}^m (h_j(\bar{x}_{t,i})-Y_j^*)^2 \right]
\]</span> where the subscript <span class="math">\(j\)</span> means the <span class="math">\(j\)</span>th entry of a vector, and <span class="math">\(m\)</span> is the dimension of features.</p>
<h3 id="feature-extraction">2.4 Feature Extraction</h3>
<p>We adopted the rectangle color features proposed by [18] as it is simple, easy-to-calculate, and retains spatial information. To extract features from a rectangle region of a grayscale image, the region is at first divide into <span class="math">\(K_1 \times K_2\)</span> small rectangles. Each small rectangle has approximately the same size. An average value of each small rectangle is calculated and concatenated as a vector. For an RGB true color image, the same operations are applied for each of the three layers, and the resulting average values form a feature vector.</p>
<p>The calculation of the average value for each small rectangle is based on the integral format of the image [18]. In the integral format, the value at <span class="math">\((a,b)\)</span> is calculated as <span class="math">\[
    R&#39;(a,b)=\sum_{i\leq a} \sum_{j\leq b} R(i,j)
\]</span> where <span class="math">\(R&#39;(a,b)\)</span> is the value at <span class="math">\((a,b)\)</span> in integral format, and <span class="math">\(R(a,b)\)</span> is the value at <span class="math">\((a,b)\)</span> in original format. Suppose the left-top corner of a small rectangle <span class="math">\(R_i\)</span> is located at <span class="math">\((a_L, b_T)\)</span>, and the right-bottom corner is located at <span class="math">\((a_R, b_B)\)</span>, then the average value can be calculated as <span class="math">\[
    \bar{R}_i =\frac{1}{|R_i|}\left[ R&#39;(a_L,b_T)+R&#39;(a_R, b_B)-R&#39;(a_L, b_B) - R&#39;(a_R, b_T) \right]
\]</span> where <span class="math">\(\bar{R}_i\)</span> denotes the average value, and <span class="math">\(|R_i|\)</span> denotes the number of pixels in <span class="math">\(R_i\)</span>.</p>
<p>A drawback of this feature is the influence from the background. The feature extraction method assumes that objects are rectangles. When objects are not rectangular, an extra of background will be incorporated into the feature vector, which leads to nonstability of features. To decrease the influence, a weight can be attached to each element in the feature vector. For small rectangles located in the middle of the object, the weights are large. And for small rectangles located on the edge of the object, the weights are small. Then the measurement model in Section 3.3 can be modified as <span class="math">\[
    w_{t,i} \propto \exp \left[ \frac{1}{\sigma^2}\sum_{j=1}^m w&#39;_j(h_j(\bar{x}_{t,i})-Y_j^*)^2 \right]
\]</span> here <span class="math">\(w&#39;_j\)</span> is the weight for the <span class="math">\(j\)</span>th entry in the feature vector.</p>
<h3 id="multiple-templates">2.5 Multiple Templates</h3>
<p>As mentioned before, a tank can have four different appearances. Therefore, a single target should have multiple templates. For each template <span class="math">\(j\)</span>, we calculate the weight <span class="math">\(w_{i,j}\)</span> for each predicted particle <span class="math">\(\bar{x}_{t,i}\)</span> using our measurement model. And the final weight of a particle <span class="math">\(\bar{x}_{t,i}\)</span> is the maximum weight in <span class="math">\(\{ w_{i,1},w_{i,2},\cdots \}\)</span>. Associate with each final weight, a template is selected for each particle. The template which is selected most of the times is considered as the expected template, which defines the width and height of the object.</p>
<h2 id="experiments">3. Experiments</h2>
<h3 id="experiment-description">3.1 Experiment Description</h3>
<p>The program was implemented on the platform MATLAB 2010b. Two cases were considered: the first case had only one target (single player), and the second case had two targets (two players). In both cases, one target had four templates depicting the appearance of the tank in four orientations.</p>
<p>In our study, each object was tracked by an independent particle filter. In initialization of each particle filter, particles were randomly generated to cover the entire image. After some steps, particles were expected to converge to their objects. Therefore, we solved a global localization problem.</p>
<p>The covariance of the noise in prediction model was set as <span class="math">\[ 
    \Sigma_{\epsilon}=\begin{bmatrix}
    2500 &amp; 0 \\
    0 &amp; 2500
    \end{bmatrix}
\]</span> and the variance of the noise in measurement model was set as <span class="math">\(\sigma=100\)</span>. The number of particles for each particle filter is 1000. Since tanks were approximately rectangular, all dimensions of the feature vector were regarded as equal weight.</p>
<h3 id="experiment-results">3.2 Experiment Results</h3>
<p>The first case consists four templates and 1876 consecutive images in size <span class="math">\(1106 \times 578\)</span>. The second case consists eight templates and 1625 consecutive images in the same size. Since the second is more general than the first case, I only describe the result of the second case here.</p>
<p>The particles begin with global randomness. Figure 4 depicts the particles and estimations of two tanks after one iteration of prediction and updating. The red points are particles of the yellow tank (left), and the blue points are particles of the green tank (right). The red and blue rectangles are the expected position of the two tanks respectively. In this figure, particles tend to concentrate on the walls, and only a few particles are located at black areas.</p>
<center>
<a href="../../post-attachments/4/step1.png"><img src="../../post-attachments/4/step1.png" alt="Figure 4: Particles and estimations of two tanks after one iteration of prediction and updating" width="625"></a>
</center>
<p>After five steps, particles converge rapidly, as Figure 5 shows.</p>
<center>
<a href="../../post-attachments/4/step5.png"><img src="../../post-attachments/4/step5.png" alt="Figure 5: Particles and estimations of two tanks after five iterations" width="625"></a>
</center>
<p>The tracking of the yellow tank is less stable than the tracking of the green tank, which can also be seen in Figure 6. An explanation is that the yellow tank is less different with the color of walls than the blue tank, in RGB values.</p>
<center>
<a href="../../post-attachments/4/stepn.png"><img src="../../post-attachments/4/stepn.png" alt="Figure 6: The red particles are more dispersive the the blue ones" width="625"></a>
</center>
<p>In conclusion, our method successfully tracks the two tanks. The output video is displayed below</p>
<iframe width="560" height="315" src="//www.youtube.com/embed/d-xK6DuUcZQ" frameborder="0" allowfullscreen>
</iframe>
<h2 id="summary-and-conclusions">4. Summary and Conclusions</h2>
<p>This study employs particle filters to track tanks in the famous game “Battle City”. Rectangle color features are used as measurements. Each object is tracked by an independent particle filter. One contribution of this study is the utilization of multiple templates to solve the problem when targets have different appearance in different occasions. The results of the experiments show that our method is capable to track the targets of interests.</p>
<h2 id="acknowledgement">5. Acknowledgement</h2>
<p>This is a course project for “Applied Estimation” in KTH, Sweden. Thank Prof. Folkesson for his instruction. Also thank Yixing Liu, my partner in this project, for her effort.</p>
<h2 id="reference">Reference</h2>
<p>[1] Dieter Koller, Joseph Weber, and Jitendra Malik. <em>Robust multiple car tracking with occlusion reasoning</em>. Springer, 1994.</p>
<p>[2] Stephen S Intille, James W Davis, and Aaron F Bobick. Real-time closed-world tracking. In <em>Computer Vision and Pattern Recognition, 1997. Proceedings., 1997 IEEE </em>Computer Society Conference on*, pages 697-703. IEEE, 1997.</p>
<p>[3] Rajeev Sharma and Jose Molineros. Role of computer vision in augmented virtual reality. In <em>IS&amp;T/SPIE’s Symposium on Electronic Imaging: Science &amp; Technology</em>, pages 220-231. International Society for Optics and Photonics, 1995.</p>
<p>[4] Kevin Cannons. A review of visual tracking. <em>Dept. Comput. Sci. Eng., York Univ., Toronto, Canada, Tech. Rep. CSE-2008-07</em>, 2008.</p>
<p>[5] Hanxuan Yang, Ling Shao, Feng Zheng, Liang Wang, and Zhan Song. Recent advances and trends in visual tracking: A review. <em>Neurocomputing</em>, 74(18):3823-3831, 2011.</p>
<p>[6] Pierre F Gabriel, Jacques G Verly, Justus H Piater, and Andre Genon. The state of the art in multiple object tracking under occlusion in video sequences. In <em>Advanced Concepts for Intelligent Vision Systems</em>, pages 166-173, 2003.</p>
<p>[7] Alper Yilmaz, Omar Javed, and Mubarak Shah. Object tracking: A survey. <em>Acm computing surveys (CSUR)</em>, 38(4):13, 2006.</p>
<p>[8] Christopher Richard Wren, Ali Azarbayejani, Trevor Darrell, and Alex Paul Pentland. Pfinder: Real-time tracking of the human body. <em>Pattern Analysis and Machine Intelligence, IEEE Transactions on</em>, 19(7):780-785, 1997.</p>
<p>[9] CH Anderson, PJ Burt, and GS Van Der Wal. Change detection and tracking using pyramid transform techniques. In <em>1985 Cambridge Symposium</em>, pages 72-78. International Society for Optics and Photonics,1985.</p>
<p>[10] Daniel J Dailey, Fritz W Cathey, and Suree Pumrin. An algorithm to estimate mean traffic speed using uncalibrated cameras. <em>Intelligent Transportation Systems, IEEE Transactions on</em>, 1(2):98-107, 2000.</p>
<p>[11] Markus Enzweiler, Richard P Wildes, and Rainer Herpers. Unified target detection and tracking using motion coherence. In <em>Application of Computer Vision, 2005. WACV/MOTIONS’05 Volume 1. Seventh IEEE Workshops on</em>, volume 2, pages 66-71. IEEE, 2005.</p>
<p>[12] Kenji Okuma, Ali Taleghani, Nando De Freitas, James J Little, and David G Lowe. A boosted particle filter: Multitarget detection and tracking. In <em>Computer Vision-ECCV 2004</em>, pages 28-39. Springer, 2004.</p>
<p>[13] John Canny. A computational approach to edge detection. <em>Pattern Analysis and Machine Intelligence, IEEE Transactions on</em>, (6):679-698, 1986.</p>
<p>[14] Dorin Comaniciu, Visvanathan Ramesh, and Peter Meer. Kernel-based object tracking. <em>Pattern Analysis and Machine Intelligence, IEEE Transactions on</em>, 25(5):564-577, 2003.</p>
<p>[15] Changjiang Yang, Ramani Duraiswami, and Larry Davis. Fast multiple object tracking via a hierarchical particle filter. In <em>Computer Vision, 2005. ICCV 2005. Tenth IEEE International Conference on</em>, volume 1, pages 212-219. IEEE, 2005.</p>
<p>[16] S. Thrun, W. Burgard, and D. Fox. <em>Probalistic robotics</em>. MIT Press, 2005.</p>
<p>[17] James L Crowley, Patrick Stelmaszyk, and Christophe Discours. Measuring image flow by tracking edge-lines. In <em>Computer Vision., Second International Conference on</em>, pages 658-664. IEEE, 1988.</p>
<p>[18] Paul Viola and Michael J Jones. Robust real-time face detection. <em>International journal of computer vision</em>, 57(2):137-154, 2004.</p>
<p>[19] Zia Khan, Tucker Balch, and Frank Dellaert. An mcmc-based particle filter for tracking multiple interacting targets. In <em>Computer Vision ECCV 2004</em>, pages 279-290. Springer, 2004.</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="introduction">1. Introduction</h2>
<h3 id="review-of-visual-object-tracking">1.1 Review of Visual Object Tracking</h3>
<p>Visual o]]>
    </summary>
    
      <category term="visual object tracking" scheme="http://songcy.net/tags/visual-object-tracking/"/>
    
      <category term="Battle City" scheme="http://songcy.net/tags/Battle-City/"/>
    
      <category term="particle filter" scheme="http://songcy.net/tags/particle-filter/"/>
    
      <category term="academic practice" scheme="http://songcy.net/categories/academic-practice/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[A Summary of State-space Models]]></title>
    <link href="http://songcy.net/posts/summary-of-state-space-models/"/>
    <id>http://songcy.net/posts/summary-of-state-space-models/</id>
    <published>2014-12-09T16:00:00.000Z</published>
    <updated>2014-12-09T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<h2 id="bayesian-filter">1. Bayesian Filter</h2>
<p>In this article, I summarize some famous state-space models. Here I won’t go into details but focus on the entire map to get an overview. All these state-space models originate from Bayesian filter. In these models, two stochastic processes are considered. The first process is <strong>states</strong> <span class="math">\(x_t\)</span>, and the second process is <strong>observations</strong> or <strong>measurements</strong> <span class="math">\(y_t\)</span>, where <span class="math">\(t\)</span> means “time” but generally the processes are not restricted to time series. We are interested in the true value of states, but we can only observe the value of observations. Therefore, state-space models aim to estimate states based on observations. Two relationships should be addressed:</p>
<ul>
<li>The state-to-state probability <span class="math">\(P(x_t | x_{1:t-1})\)</span></li>
<li>The state-to-observation probability <span class="math">\(P(y_t | x_t)\)</span> No <em>direct</em> relationship exists between any two observations. A common assumption is the Markov property, which assumes that the current state depends only on the previous state, namely <span class="math">\(P(x_t | x_{1:t-1})=P(x_t|x_{t-1})\)</span>.</li>
</ul>
<h2 id="prediction-and-updating">2. Prediction and Updating</h2>
<p>State-space model has online algorithms with recursive two steps. Prediction is to estimate the posterior distribution <span class="math">\(p(x_t | y_{1:t-1})\)</span> based on the distribution <span class="math">\(p(x_{t-1}| y_{1:t-1})\)</span>, according to the state-to-state probability <span class="math">\(P(x_t|x_{t-1})\)</span>. Mathematically, <span class="math">\[
    p(x_t|y_{1:t-1})=\int p(x_t|x_{t-1}) p(x_{t-1}|y_{1:t-1}) dx_{t-1}
\]</span> Updating is to update the previous distribution based on the latest observation <span class="math">\(y_t\)</span>. Mathematically, <span class="math">\[
    p(x_t | y_{1:t})= p(y_t|x_t) p(x_t|y_{1:t-1}) /p(y_t) \propto p(y_t|x_t) p(x_t|y_{1:t-1})
\]</span></p>
<h2 id="considerations-in-modeling">3. Considerations in Modeling</h2>
<p>Bayesian filters estimate <span class="math">\(x_t\)</span> by the posterior distribution <span class="math">\(p(x_t | y_{1:t})\)</span>. Usually the state-to-state probability and state-to-observation probability cannot be obtained directly when modeling practical problems. Instead, they should be inferred from prediction model <span class="math">\(x_t=f(x_{t-1})\)</span> and measurement model <span class="math">\(y_t=g(x_t)\)</span>. And a series of questions must be answered:</p>
<ul>
<li>Is state <span class="math">\(x_t\)</span> discrete or continuous?</li>
<li>What is the distribution of <span class="math">\(x_t\)</span>?</li>
<li>Is the prediction model linear or nonlinear?</li>
<li>Is the measurement model linear or nonlinear? According to different answers to these questions, we have different filters as follows.</li>
</ul>
<p><a href="../../post-attachments/3/structure-of-bayesian-filters.png"><img src="../../post-attachments/3/structure-of-bayesian-filters.png" alt="" width="625" height="364"></a></p>
<h2 id="classification-of-bayesian-filters">4. Classification of Bayesian filters</h2>
<p>Based on whether the state <span class="math">\(x_t\)</span> is discrete or continuous, Bayesian filters are divided into discrete filters and continuous filters. When state <span class="math">\(x_t\)</span> can only be discrete values, the state-to-state probability can be expressed by transition matrix <span class="math">\(A=[a_{i,j}]\)</span> where <span class="math">\(a_{i,j}=P(x_t =j|x_{t-1}=i)\)</span>.</p>
<p>Based on whether the distribution of <span class="math">\(x_t\)</span> is assumed to be a specific format, continuous Bayesian filters are divided into parametric and nonparametric filters. For example , in Gaussian filters, the distribution of <span class="math">\(x_t\)</span> is assumed to be multivariate normal distribution. With this assumption, the posterior distribution <span class="math">\(p(x_t|y_{1:t})\)</span> can be expressed in close-form explicitly. On the other side, non-parametric filters don’t make any assumptions in the distribution of <span class="math">\(x_t\)</span>, but use some techniques to approximate the distribution. For example, the distribution of <span class="math">\(x_t\)</span> can be expressed by a histogram (Histogram filter) or a lot of samples (Particle filter) drawn from the target distribution. Non-parametric filters approximate the distribution, and put no restrictions on prediction model <span class="math">\(x_t=f(x_{t-1})\)</span> and measurement model <span class="math">\(y_t=g(x_t)\)</span>, thus flexible in various situations. However, the computation load is heavy since there is no close-form expression, and the better of the approximation, the heavier of the computation burden.</p>
<p>Gaussian filters assume the distribution of <span class="math">\(x_t\)</span> to be multivariate normal distribution. In classical Kalman filter, the prediction model <span class="math">\(x_t=f(x_{t-1})\)</span> and the measurement model <span class="math">\(y_t=g(x_t)\)</span> are assumed linear in order to maintain normality. Specifically, <span class="math">\(x_t=A x_{t-1}+ \epsilon_t, y_t=B x_t + \delta_t\)</span>. Derivatives of Kalman filter such as Extended Kalman filter and Uncented Kalman filter relax the linear relationship assumption, but approximate by linearization techniques such as Taylor expansion. Information filter and its derivatives are essentially the same to Kalman filter family, with information expression of multivariate normal distribution <span class="math">\(\Omega=\Sigma^{-1}, \xi=\Omega \mu\)</span>.</p>
<p>Hybrid filters are mixture of parametric and non-parametric filters, with some dimensions of state assumed to be in specific format and other dimensions to be expressed in non-parametric techniques.</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="bayesian-filter">1. Bayesian Filter</h2>
<p>In this article, I summarize some famous state-space models. Here I won’t go into detai]]>
    </summary>
    
      <category term="state-space model" scheme="http://songcy.net/tags/state-space-model/"/>
    
      <category term="Bayesian filter" scheme="http://songcy.net/tags/Bayesian-filter/"/>
    
      <category term="academic theory" scheme="http://songcy.net/categories/academic-theory/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[From Vector to Function — Transformations, Basis, and Kernel Method]]></title>
    <link href="http://songcy.net/posts/vector-to-function-basis-kernel/"/>
    <id>http://songcy.net/posts/vector-to-function-basis-kernel/</id>
    <published>2014-10-10T16:00:00.000Z</published>
    <updated>2014-10-10T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Here is only some superficial thought about Fourier transformation (and other similar transformations), space basis, and kernel method. I will continuously update the post for new thoughts.</p>
<h2 id="what-is-function">1. What is function</h2>
<p>A function is an infinite vector. Every thought begins here. As the following figure shows</p>
<center>
<a href="../../post-attachments/2/Signal_Sampling.png"><img src="../../post-attachments/2/Signal_Sampling.png" alt="source: http://en.wikipedia.org/wiki/Sampling_(signal_processing)" width="379" height="246"></a>
</center>
<p>For a function defined on the interval <span class="math">\([a,b]\)</span>, we take samples by an interval <span class="math">\(\Delta x\)</span>. If we sample the function <span class="math">\(f(x)\)</span> at points <span class="math">\(a, x_1,\cdots,x_n,b\)</span>, then we can transform the function into a vector <span class="math">\((f(a),f(x_1),\cdots,f(x_n),f(b))^T\)</span>. When <span class="math">\(\Delta x\rightarrow 0\)</span>, the vector should be more and more close to the function and at last, it becomes infinite.</p>
<p>The above analysis assumes <span class="math">\(x\)</span> to be a real number. But when <span class="math">\(x\)</span> is a vector, it still holds. From now on, we use bold font such as <span class="math">\(\mathbf{x}\)</span> to denote normal vector in <span class="math">\(\mathcal{R}^n\)</span> space; use <span class="math">\(f\)</span> to denote the function itself, namely the infinite vector; use <span class="math">\(f(\mathbf{x})\)</span> to denote the evaluation of the function at point <span class="math">\(\mathbf{x}\)</span>. And the evaluation of a function should be a real number.</p>
<h2 id="function-inner-product">2. Function inner product</h2>
<p>Vectors have inner product. For vector <span class="math">\(\mathbf{x}=(x_1,\cdots,x_n)\)</span> and <span class="math">\(\mathbf{y}=(y_1, \cdots, y_n)\)</span>, the inner product of <span class="math">\(\mathbf{x}\)</span> and <span class="math">\(\mathbf{y}\)</span> is defined as <span class="math">\[
    &lt;\mathbf{x},\mathbf{y}&gt;=\sum_{i=1}^n x_i y_i
\]</span> Similarly, functions have inner product. For two functions <span class="math">\(latex f\)</span> and <span class="math">\(latex g\)</span> sampling by interval <span class="math">\(latex \Delta x\)</span>, the inner product may be defined as <span class="math">\[
    &lt;f,g&gt;=\lim_{\Delta x\rightarrow 0}\sum_{i} f(x_i) g(x_i)
\]</span> at first thought. However, the above equation doesn’t converge when <span class="math">\(\Delta x\rightarrow 0\)</span>. Something is missing. As <span class="math">\(x\)</span> approaches 0, the dimension of <span class="math">\(f\)</span> and <span class="math">\(g\)</span> grows larger in our denotation.</p>
<p>For a vector, the dimension is discrete. We only have the first, second,… dimension. But we don’t have the 0.5, 1.5,… dimension. When we transform a function into a vector, every sample point is located at a discrete dimension. However, this should not be true, since the dimension of each sample point should be stable so that the above equation will converge. Therefore, the dimension is not discrete for functions, but continuous. What we miss is the difference between adjacent dimensions for normalization. Therefore, we can define the inner product of two functions as <span class="math">\[
    &lt;f,g&gt;=\lim_{\Delta x\rightarrow 0}\sum_{i} f(x_i) g(x_i)\Delta x=\int f(x)g(x)dx
\]</span></p>
<h2 id="basis">3. Basis</h2>
<p>What is the meaning of inner product? For two vectors <span class="math">\(A\)</span> and <span class="math">\(B\)</span>, the inner product is the projection of one vector to the other.</p>
<center>
<a href="../../post-attachments/2/1000px-Dot_Product.png"><img src="../../post-attachments/2/1000px-Dot_Product.png" alt="" width="250" height="200"></a>
</center>
<p><span class="math">\[
    &lt;A,B&gt;=|A||B|\cos\theta
\]</span> Namely <span class="math">\[
    \mathrm{projection}(A) = \frac{&lt;A,B&gt;}{|B|^2} B
\]</span> If we regard the length of <span class="math">\(B\)</span> as one unit, then the inner product is the coordinate of the projection on <span class="math">\(B\)</span>. Therefore, given a set of orthogonal basis vector <span class="math">\(\{\mathbf{e}_i\}_{i=1}^n\)</span> where <span class="math">\(&lt;\mathbf{e}_i,\mathbf{e}_j&gt;=0\)</span> and <span class="math">\(|\mathbf{e}_i|=1\)</span>. The basis vectors can establish a space by linear operations. Any vector <span class="math">\(\mathbf{x}\)</span> in the space can be denoted as <span class="math">\[
    \mathbf{x}=\sum_{i=1}^n &lt;\mathbf{x},\mathbf{e}_i&gt; \cdot \mathbf{e_i}
\]</span> More generally, if <span class="math">\(|\mathbf{e}_i| \neq 1\)</span>, then <span class="math">\[
    \mathbf{x}=\sum_{i=1}^n \frac{&lt;\mathbf{x},\mathbf{e}_i&gt;}{|\mathbf{e}_i|^2} \mathbf{e}_i=\sum_{i=1}^n \frac{&lt;\mathbf{x},\mathbf{e}_i&gt;}{&lt;\mathbf{e}_i,\mathbf{e}_i&gt;} \mathbf{e}_i
\]</span> Functions also have basis, which can be orthogonal or non-orthogonal. If we define the set of function basis, any function in the space can also be decomposed into the combination of several basis functions. Function inner product can also be used to calculate the coefficient on any specific basis. However, since the dimension of function is continuous, there may be infinite basis functions.</p>
<p>For a set of function basis <span class="math">\(\{h_i\}\)</span>, if <span class="math">\(&lt;h_i,h_j&gt;=0\)</span> and <span class="math">\(|h_i|=1\)</span>, any function within the space can be denoted as <span class="math">\[
    f=\sum &lt;f,h_i&gt; \cdot h_i=\sum_i \int f(x)h_i(x)dx \cdot h_i
\]</span> If <span class="math">\(|h_i| \neq 1\)</span>, <span class="math">\[
    f=\sum_i \frac{&lt;f,h_i&gt;}{&lt;h_i,h_i&gt;} h_i
\]</span> similar to the vector case.</p>
<h2 id="example-transformations">4. Example: Transformations</h2>
<p>Let the basis functions <span class="math">\(\{h_p\}, (p\)</span> is interger) be <span class="math">\[
    h_p(x)=e^{i2\pi p x/T}
\]</span> defined on interval <span class="math">\([0, T]\)</span>. Here I use <span class="math">\(p\)</span> to index the basis functions in order to distinguish from the imaginary number <span class="math">\(i\)</span>. These construct a space and any function defined on interval <span class="math">\([0, T]\)</span> is within the space. It can be proven that any two basis function are orthogonal (for complex numbers, the latter term should take conjugate transpose when calculating the inner product). <span class="math">\[
    &lt;h_p, h_q&gt;=\int_0^T h_p (x) \bar{h_q(x)} dx=\int_0^T e^{i2\pi p x/T} e^{-i2\pi q x/T} dx=0
\]</span> where <span class="math">\(p \neq q\)</span> and <span class="math">\(\bar{a+bi}=a-bi\)</span>. The “length” of basis is <span class="math">\[
    |h_p|^2=&lt;h_p,h_p&gt;=T
\]</span> If a function <span class="math">\(latex f\)</span> defined on interval <span class="math">\([0,T]\)</span> is within the space, it can be written as <span class="math">\[
    f(x)=\sum_p c_p h_p(x)=\sum_p c_p e^{i2\pi px/T}
\]</span> And the coefficient can be calculated as <span class="math">\[
    c_p=\frac{&lt;f,h_p&gt;}{|h_p|^2}=\frac{1}{T} \int_0^T f(x)\bar{h_p(x)}dx=\frac{1}{T} \int_0^T f(x) e^{-i2\pi p x} dx
\]</span> Actually this is the Fourier series. A more thorough discussion about Fourier series can be found <a href="http://www.thefouriertransform.com/" target="_blank" rel="external">here</a>.</p>
<h2 id="kernel-function">5. Kernel Function</h2>
<p>Instead of <span class="math">\(i\)</span>, we use <span class="math">\(y\)</span> to index the basis function. Let <span class="math">\[
    K(x,y)=h_y(x)
\]</span> The set of basis functions can be denoted as one function with two parameters. In the example, <span class="math">\(y\)</span> is discrete. However, this is not the full space. If we let <span class="math">\(y\)</span> to be real number, then any functions may be represented.</p>
<p>The function <span class="math">\(K(x,y)\)</span> is kernel function. It may be viewed as a cluster of basis functions. If they are orthogonal <span class="math">\(&lt;K(\cdot,y_1),K(\cdot,y_2)&gt;=0\)</span> for any <span class="math">\(y_1 \neq y_2\)</span>, and the squared “length” of basis <span class="math">\(|K(\cdot,y)|^2=\int 1 dx\)</span>, any function <span class="math">\(f\)</span> can be represented as <span class="math">\[
    f=\int F(y)K(\cdot,y) dy
\]</span> And the coefficient of a function <span class="math">\(f\)</span> on a basis <span class="math">\(K(\cdot,y)\)</span> is calculated as <span class="math">\[
    F(y)=&lt;f,K(\cdot,y)&gt;=\int f(x)K(x,y)dx
\]</span> Therefore, kernel function is able to transform a function into another space (a function space).</p>
<h2 id="example-transformations-1">6. Example: Transformations</h2>
<p>Let the kernel function to be <span class="math">\[
    K(x,y)=e^{i2\pi xy}
\]</span> where <span class="math">\(i\)</span> is the imaginary number. It is easy to show that the basis functions are mutual orthogonal, <span class="math">\[
    &lt;K(\cdot,y_1),K(\cdot,y_2)&gt;=\int K(x,y_1) \bar{K(x,y_2)}dx=\int e^{i2\pi xy_1}e^{-i2\pi xy_2}dx=0
\]</span> when <span class="math">\(y_1 \neq y_2\)</span>. Then squared “length” of basis is <span class="math">\[
    &lt;K(\cdot,y),K(\cdot,y)&gt;=\int K(x,y)\bar{K(x,y)} dx=\int 1 dx
\]</span> This constitutes a full function space. The coefficient is calculated as <span class="math">\[
    F(y)=&lt;f,K(\cdot ,y)&gt;=\int f(x) \bar{K(x,y)} dx=\int f(x)e^{-i2\pi xy}dx
\]</span> The original function is represented as <span class="math">\[
    f(x)=\int F(y) K(x,y) dy=\int F(y) e^{i2\pi xy}dy
\]</span> Actually this is the Fourier transformation. Other transformations such as Laplace transformation, Z-transformation are similar. Maybe wavelet is also within the framework.</p>
<h2 id="something-about-kernel-method">7. Something about Kernel Method</h2>
<p>For a kernel function <span class="math">\(K(x,y)\)</span>, if we regard it as a cluster of basis, then we can get a space by the linear combination of the basis. However, the basis may not be orthogonal. This is somewhat like a matrix <span class="math">\(P\)</span>, if we use the columns of <span class="math">\(P\)</span> to generate a space. To construct orthogonal basis for the space, we can use eigen value and eigen vectors of <span class="math">\(P\)</span>. Similarly, we can use eigenfunctions as the basis for the function space generated by <span class="math">\(K(x,y)\)</span>. If all the eigen values are positive, then the kernel function is positive. If the inner product is defined as <span class="math">\[
    &lt;K(\cdot,x), K(\cdot,y)&gt;=K(x,y)
\]</span> This is the reproducing kernel Hilbert space. It is commonly used to calculate the inner product of two mappings in a high-dimension feature space. When linear model is not enough, we can map the points into feature space and use kernel trick to calculate inner product. Support Vector Machine is an example.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Here is only some superficial thought about Fourier transformation (and other similar transformations), space basis, and kernel method. I]]>
    </summary>
    
      <category term="Fourier transform" scheme="http://songcy.net/tags/Fourier-transform/"/>
    
      <category term="function basis" scheme="http://songcy.net/tags/function-basis/"/>
    
      <category term="kernel method" scheme="http://songcy.net/tags/kernel-method/"/>
    
      <category term="academic theory" scheme="http://songcy.net/categories/academic-theory/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[A Preliminary Introduction about Hadoop — Concepts and Ideas]]></title>
    <link href="http://songcy.net/posts/introduction-about-hadoop-concepts/"/>
    <id>http://songcy.net/posts/introduction-about-hadoop-concepts/</id>
    <published>2014-10-01T16:00:00.000Z</published>
    <updated>2014-10-01T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>I have spent several days in studying Hadoop. Here I would like to write some notes about the concept and ideas behind the Hadoop project. This blog will not show any technique details, but focus on the preliminary ideas. You can download the PDF slides <a href="../../post-attachments/1/Preliminary-study-about-Hadoop-Songcy.pdf">here</a>.</p>
<h2 id="background">1. Background</h2>
<p>“Big data” — this word is everywhere. We are living in the century of data. The amount of data grows explosively. The following figure predicts the amount of data in the next few years. From the figure we know that the growth of data is quite rapid.</p>
<center>
<a href="../../post-attachments/1/growth-of-data.jpg"><img src="../../post-attachments/1/growth-of-data.jpg" alt="" width="474" height="359"></a>
</center>
<p>In accordance with the growth of data, the storage capacity of hard drives also increased massively. However, the access speed (the data transfer rate in reading and writing) has not kept up, which means we have to spend a lot of time for data reading and data writing, compared to the capacity of hard drives. The following figure compares the capacity and data transfer performance of hard drives. As it shows, the difference becomes more and more significant.</p>
<center>
<a href="../../post-attachments/1/comparison-of-capacity-and-transfer-rate.jpg"><img src="../../post-attachments/1/comparison-of-capacity-and-transfer-rate.jpg" alt="Source: http://www.cs.ucla.edu/classes/winter13/cs111/scribe/10c/f" width="632" height="260"></a>
</center>
<p>Currently if we have 1TB of data on a hard disk, we need more than 2.5 hours to read all the data! Therefore, in the age of big data, the low data access speed is the bottle neck for data storage, retrieval, and analysis. How to deal with the bottle neck? Some people came up with the idea of multiple hard drives and parallel computing.</p>
<p>The following figure demonstrates a coarse model for multiple hard drives. At first, we split our data into pieces. Each piece of data is stored on a separate hard drive. When we want to analyze the data, each hard drive will read and process one piece of data respectively. Then the results are merged to get the final conclusion. Since one hard drive only need to read a piece of data, the data access time can be shortened.</p>
<center>
<a href="../../post-attachments/1/a-coarse-model-for-multiple-hard-drives1.png"><img src="../../post-attachments/1/a-coarse-model-for-multiple-hard-drives1.png" alt="" width="539" height="357"></a>
</center>
<p>One question may be as follows:</p>
<blockquote>
<p>Isn’t it a waste of hard drive space if we use multiple drives to store only one dataset?</p>
</blockquote>
<p>Yes, it is really a waste of space. However, imagine if we have multiple datasets (or multiple users of this system), we can do the same to all the datasets. Then the space of hard drives can be more efficiently utilized. At the same time, the data access time for each dataset will be shortened as long as we don’t analyze all datasets at the same time!</p>
<p>Then we may want to build one such kind of system. But we will confront some problems. The first problem is about hardware failure rate. Although an individual hardware has a relatively low failure rate, the failure rate of a group of hard drives will be high, since the system fails as long as one of the drives fails. The second problem is in which way can we combine the data from multiple drives? There are also other problems need to be addressed.</p>
<p>With consideration of these problems, Hadoop is such kind of system for distributed computing! The Hadoop project provides you the concept, ideas and framework. It also offers a system for installation. You can install the Hadoop system on a single machine or on a group of computers. It is somewhat like the operating system designed for computer cluster. Hadoop also provides libraries so that you can write your own applications to interact with the system, and to analyze your own dataset.</p>
<h2 id="overview-of-hadoop">2. Overview of Hadoop</h2>
<p>Hadoop is a top project. It has several subprojects. Each subproject deals with one aspect of distributed computing. The following is a list of Hadoop subprojects, but not the full list.</p>
<ul>
<li>HDFS: a distributed filesystem</li>
<li>MapReduce: a distributed data processing model and execution environment</li>
<li>Pig: a data flow language and execution environment for exploring very large datasets</li>
<li>HBase: a distributed, column-oriented database</li>
<li>ZooKeeper: a distributed, highly available coordination service</li>
<li>Hive: a distributed data warehouse</li>
</ul>
<p>This a graphic demonstration of Hadoop subprojects.</p>
<center>
<a href="../../post-attachments/1/Hadoop-subprojects.png"><img src="../../post-attachments/1/Hadoop-subprojects.png" alt="" width="458" height="269"></a>
</center>
<p>Two important subprojects are HDFS and MapReduce, which are designed for data storage and data analysis respectively. These two parts provide systematical solution to the pre-mentioned problems.</p>
<h2 id="hadoop-subprojects">3. Hadoop Subprojects</h2>
<h3 id="hdfs">3.1 HDFS</h3>
<p>HDFS is short for Hadoop Distributed FileSystem. As you can see from the name, it manages the storage across a network of machines. HDFS is suitable for</p>
<ul>
<li>Very large files (GB or TB sized)</li>
<li>Streaming data access (write once, read many times)</li>
<li>Commodity hardware (it doesn’t require expensive or special hardware)</li>
</ul>
<p>HDFS is not suitable for</p>
<ul>
<li>Low-latency data access (HDFS needs some time to find the location of the file)</li>
<li>Lots of small files (i.e. billions of small files)</li>
<li>Multiple writers, arbitrary file modifications The reason lies in the mechanism of HDFS. The structure of HDFS is like this.</li>
</ul>
<center>
<a href="../../post-attachments/1/HDFS-structure.png"><img src="../../post-attachments/1/HDFS-structure.png" alt="" width="557" height="280"></a>
</center>
<p>Files in HDFS are broken into equal-sized blocks (e.g. 64MB). The block size is the minimum amount of data that the system can read or write. Blocks from the same file are stored independently. As mentioned before, a group of hard drives is not reliable. Thus each block is replicated (e.g. 3 copies) in case of hardware corruption.</p>
<p>Datanodes are workers. A datanode is responsible for storing and retrieving file blocks. It also reports to namenode periodically with the list of blocks that it is storing. I think a datanode can be regarded as a computer in the network.</p>
<p>Namenode is the heart of the system, the master. It maintains the filesystem tree and metadata for all the files and directories in the tree. The tree looks like this.</p>
<center>
<a href="../../post-attachments/1/file-tree.png"><img src="../../post-attachments/1/file-tree.png" alt="" width="619" height="202"></a>
</center>
<p>At first, there is a root directory. The root contains several sub-directories. Each directory has several files and each files is divided into blocks. Since datanodes report to namenode periodically with block lists, the namenode knows which datanode that a block is located at.</p>
<p>This is the data reading process in HDFS.</p>
<center>
<a href="../../post-attachments/1/data-reading-in-HDFS.jpg"><img src="../../post-attachments/1/data-reading-in-HDFS.jpg" alt="Source: White, Tom. &quot Hadoop: The definitive guide. &quot 3rd Edition, Page 68, O'Reilly Media, Inc., 2012." width="622" height="375"></a>
</center>
<p>At first, the system will refer to the namenode to get the list of blocks of the file as well as block locations. Then the InputStream will read every blocks from the corresponding datanode simultaneously.</p>
<p>This is the data writing process of HDFS:</p>
<center>
<a href="../../post-attachments/1/data-writing-in-HDFS.jpg"><img src="../../post-attachments/1/data-writing-in-HDFS.jpg" alt="Source: White, Tom. &quot Hadoop: The definitive guide. &quot; 3rd edition, page 71, O'Reilly Media, Inc., 2012." width="654" height="401"></a>
</center>
<p>At first, the system will refer to the namenode to check if the file already exists in the system or not. If it doesn’t exist, the namenode will create the file in the filesystem tree. It also provides a list of datanodes that the blocks of the file can be stored. Then OutputStream will write each block into datanodes. Since each block is replicated several times, it is written to a pipeline of datanodes. That is, after it is written to the first datanode, it is passed to the second datanode, then the third, which can be specified by the user.</p>
<h3 id="mapreduce">3.2 MapReduce</h3>
<p>MapReduce is a parallel data-processing model for distributed computing. In this model, the work that we want to do is divided into two phases: the map phase and reduce phase. Each phase has its input and output, in a (key, value) format.</p>
<center>
<a href="../../post-attachments/1/mapreduce-structure.png"><img src="../../post-attachments/1/mapreduce-structure.png" alt="" width="473" height="224"></a>
</center>
<p>Here is an example. We want to find the highest recorded temperature for each year in the dataset. The input is a large file with each line containing various information for a specific day. In map phase, we extract year and temperature from each line. Since each line is about a day, a year contains multiple lines in the output of map phase. Thus we merge the map output for each year, which is called shuffle. Then we use reduce functions to calculate the maximum temperature for each year. The process is like this.</p>
<center>
<a href="../../post-attachments/1/mapreduce-example.jpg"><img src="../../post-attachments/1/mapreduce-example.jpg" alt="" width="681" height="110"></a>
</center>
<p>So how MapReduce used for distributed computing? In MapReduce, what we want to do is defined as a <em>job</em>. A job is divided into multiple <em>tasks</em>, including map tasks and reduce tasks. Accordingly, input dataset is split into equal-sized pieces (actually this is what HDFS does) and each task deals with one piece of dataset. <em>Jobtracker</em> and <em>tasktrackers</em> are used for coordination. The following figure shows the process of parallel computing.</p>
<center>
<a href="../../post-attachments/1/mapreduce-single.jpg"><img src="../../post-attachments/1/mapreduce-single.jpg" alt="Source: White, Tom. &quot Hadoop: The definitive guide. &quot; 3rd edition, page 32, O'Reilly Media, Inc., 2012." width="555" height="299"></a>
</center>
<p>For each split of the input dataset, we apply a map function. Then we merge the map output as the input to the reduce function to get the result. Please note that map functions can be done simultaneously but reduce phase always follows map phase. If we have multiple reduce functions, the process is like this:</p>
<center>
<a href="../../post-attachments/1/mapreduce-multiple.jpg"><img class=" wp-image-122" src="../../post-attachments/1/mapreduce-multiple.jpg" alt="Source: White, Tom. &quot Hadoop: The definitive guide. &quot; 3rd edition, page 33, O'Reilly Media, Inc., 2012.\" "="" width="581" height="313"></a>
</center>
<p>Hadoop does its best to run map task on the computer where input split resides in HDFS, which is called data locality optimization. That is, the computer where the input split is located, is responsible for running map task on the input split. If we use another computer, the input split must be transferred to the computer through the network, which will occupy the bandwidth resource. Therefore, data locality decreases the data transfer through the network. However, reduce tasks don’t have the advantage of data locality. All the output of map functions must be transferred to a specific node for reduce task. In order to minimize data transfer, combiner functions can be used between map and reduce to discard unnecessary information in map output. Take the highest temperature as an example. A combiner function can be applied after shuffle, to calculate the local maximum annual temperature in each split of the input dataset.</p>
<p>The following figure shows the process of a MapReduce job. At first, the job is assigned an ID for specification. Then it refers to the filesystem to get job resources such as configuration information. After the job is submitted to jobtracker, it will be initialized. The jobtracker also retrieves input splits from the filesystem and set up a map task for each split. The number of reduce tasks is determined by user configuration. Tasktrackers receive tasks and report to the jobtracker about the status of the tasks periodically.</p>
<center>
<a href="../../post-attachments/1/mapreduce-process.jpg"><img src="../../post-attachments/1/mapreduce-process.jpg" alt="Source: White, Tom. &quot Hadoop: The definitive guide. &quot; 3rd edition, page 191, O'Reilly Media, Inc., 2012." width="586" height="476"></a>
</center>
<p>There is a new system called YARN sharing similar function as MapReduce. Since I didn’t dig into this subproject, I will not discuss YARN here.</p>
<p>MapReduce deals with low-level operations. With only MapReduce, we have to care about the data flow details. Therefore, we need some advanced tools to help us focus on data itself and deal with the technique details. In the next subsection, I will introduce three high-level subprojects.</p>
<h3 id="other-subprojects">3.3 Other Subprojects</h3>
<h4 id="pig">3.3.1 Pig</h4>
<p>Pig is the language and execution environment for processing large datasets. Pig consists of two pieces: Pig Latin, which is the language to express data flow, and the execution environment to run Pig Latin programs.</p>
<p>Pig Latin program consists of a series of operations or transformations applied to input data. It can be translated into a series of MapReduce jobs by Pig execution environment so that the Pig Latin language can be understood by Hadoop system. Take the highest recorded temperature for example. With Pig, we only need a few lines to complete the work.</p>
<center>
<a href="../../post-attachments/1/Pig-example.jpg"><img src="../../post-attachments/1/Pig-example.jpg" alt="Source: White, Tom. &quot Hadoop: The definitive guide. &quot" width="639" height="176"></a>
</center>
<h4 id="hbase">3.3.2 HBase</h4>
<p>HBase is a distributed column-oriented database built on HDFS. Although it is a database, it doesn’t support SQL. The idea is that if the table grows too large, it is automatically partitioned into regions horizontally (each region contains multiple rows from the table). Similar to HDFS and MapReduce, it has a master-slave structure. It uses a master node to manage the whole space and regionserver slaves to manage one or more regions.</p>
<h4 id="hive">3.3.3 Hive</h4>
<p>Hive is a data warehouse infrastructure built on top of Hadoop. It supports the Hive Query language – very similar to SQL. Therefore you can get familiar with Hive very quickly if you are familiar with traditional database.</p>
<h2 id="summary">4. Summary</h2>
<p>Hadoop is a collection of subprojects used for parallel data storage, retrieval &amp; analysis in a group of computers/hardwares, in order to mitigate the data access bottleneck in hard drives.</p>
<h3 id="for-more-information">For more information</h3>
<ul>
<li>White, Tom. “Hadoop: The definitive guide.” O’Reilly Media, Inc., 2012.</li>
<li>Apache Hadoop homepage http://hadoop.apache.org/</li>
</ul>
<h3 id="reference">Reference</h3>
<ul>
<li>White, Tom. “Hadoop: The definitive guide.” O’Reilly Media, Inc., 2012.</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>I have spent several days in studying Hadoop. Here I would like to write some notes about the concept and ideas behind the Hadoop project]]>
    </summary>
    
      <category term="Hadoop" scheme="http://songcy.net/tags/Hadoop/"/>
    
      <category term="big data" scheme="http://songcy.net/tags/big-data/"/>
    
      <category term="HDFS" scheme="http://songcy.net/tags/HDFS/"/>
    
      <category term="MapReduce" scheme="http://songcy.net/tags/MapReduce/"/>
    
      <category term="technique" scheme="http://songcy.net/categories/technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[A Brief Introduction about How to Own Personal Homepage]]></title>
    <link href="http://songcy.net/posts/introduction-to-personal-homepage/"/>
    <id>http://songcy.net/posts/introduction-to-personal-homepage/</id>
    <published>2014-07-02T16:00:00.000Z</published>
    <updated>2014-07-02T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>So, this is the first post of this site. It is prepared for those who know little about the technology of coding/Internet but want to build their own homepage. At first, some concept should be addressed.</p>
<h2 id="basic-concept-step-by-step">1. Basic Concept Step by Step</h2>
<ul>
<li>Internet. The Internet is composed by a lot of computers around the world.</li>
<li>Server. Some computers provide service/resources to others. They are servers. For example, you can search on google.com since there is a server providing the search service; you can download a video from youtube.com since there is a server providing the file-transferring service.</li>
<li>IP address. If we want to get service from a specific server, we should know where it is. What’s more, if a server wants to provide service to us, it should know where our computers are. IP address is the unique address of a computer in the Internet, which providing the location of computers. For example, the IP address of google.com is 203.208.48.151</li>
<li>Static IP address and dynamic IP address. If the IP address of a computer doesn’t change in different set ups, it is static IP. Most servers require static IP. If the IP address changes after a computer is rebooted, it is a dynamic IP. Probably, the IP of many personal computers is dynamic.</li>
<li>Domain name. If we want to get access to google, we may provide its IP address. However, it is too difficult to remember. So we get a name for google (www.google.com), which is the domain name. Each domain name is in accord to a specific and unique IP, thus we can find the server by its domain name. Domain name has a hierarchical structure. For example, for “www.google.com”, “com” means “commodity”, “google” means a group of computers, “www” is the name of a specific computer which provides the web service.</li>
<li><a href="http://www.wordpress.org/" target="_blank" rel="external">WordPress</a>. This is a popular template system for websites with various themes and plugins. I use it to construct the homepage.</li>
</ul>
<h2 id="outline-of-owning-homepage">2. Outline of Owning Homepage</h2>
<ul>
<li>Get/buy a specific domain name that you like for your site</li>
<li>Get/buy a host</li>
<li>Bind the domain name and the IP address of the host</li>
<li>Build your website</li>
</ul>
<h2 id="get-a-domain-name">3. Get a Domain Name</h2>
<p>Domain name is unique on the Internet, thus you should think about one that has not been used/owned by anyone else. There are a lot of places that you can get a domain name, such as <a href="http://www.net.cn" target="_blank" rel="external">www.net.cn</a> (万网, my choice) ; <a href="https://web.easydns.com/" target="_blank" rel="external">EasyDNS</a>. There are detailed instructions on these sites. Please note that the domain name of google is “google.com” NOT “www.google.com”.</p>
<h2 id="get-a-host">4. Get a Host</h2>
<p>A host means a “server” that you need for your website to provide service to others. However, it may not be a physical computer although it is like a computer. You can get/buy a host in many ways. My choice is AWS, provided by Amazon. You can get free of charge if you limit the resources required by your host. But it is enough for personal websites.</p>
<p>However, the setting up is still complex for me if I want to build the website on <a href="http://aws.amazon.com" target="_blank" rel="external">AWS</a> by myself. There may be some errors in the supporting document of AWS and I cannot get help since I am free of charge. Therefore, I find <a href="https://bitnami.com/" target="_blank" rel="external">Bitnami</a>. Carefully configure the settings and launch a server in the console of Bitnami with the application WordPress (or some other applications). You will obtain an IP address and a domain name.</p>
<h2 id="binding">5. Binding</h2>
<p>You the bind the IP address or domain name of your host with your domain name, on the website of your domain provider.</p>
<h2 id="build-your-homepage">6. Build Your Homepage</h2>
<p>Login your website as administrator with the account and password specified when launching you host. Find a beautiful theme and customize it. It will help a lot if you get to know some about HTML/php/CSS.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>So, this is the first post of this site. It is prepared for those who know little about the technology of coding/Internet but want to bui]]>
    </summary>
    
      <category term="wordpress" scheme="http://songcy.net/tags/wordpress/"/>
    
      <category term="technique" scheme="http://songcy.net/categories/technique/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Welcome to My Homepage]]></title>
    <link href="http://songcy.net/posts/welcome-to-my-homepage/"/>
    <id>http://songcy.net/posts/welcome-to-my-homepage/</id>
    <published>2014-06-30T16:00:00.000Z</published>
    <updated>2014-06-30T16:00:00.000Z</updated>
    <content type="html"><![CDATA[<p>Hey, welcome to my homepage. I will update the website irregularly. Thank you for your attention.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Hey, welcome to my homepage. I will update the website irregularly. Thank you for your attention.</p>
]]>
    </summary>
    
      <category term="others" scheme="http://songcy.net/categories/others/"/>
    
  </entry>
  
</feed>
